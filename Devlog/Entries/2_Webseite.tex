\section{Erstellen der Webseite}
Bevor wir mit der Implementierung irgendwelcher Bildverarbeitungsalgorithmen beginnen können, müssen wir zunächst eine Webseite mit den notwendigen Funktionalitäten erstellen.

\subsection{openCV.js}
Als aller erstes braucht es natürlich eine aktuelle Version von openCV.js. Diese kann direkt von der offiziellen openCV-Webseite heruntergeladen werden:

\href{https://docs.opencv.org/4.10.0/opencv.js}{https://docs.opencv.org/4.10.0/opencv.js}

Es handelt sich hierbei um eine mittels Emscripten kompilierte Version von OpenCV, welche in JavaScript in Form einer WebAssembly ausgeführt werden kann. Das Einbinden erfolgt wie mit einer gewöhnlichen JavaScript-Datei. Da der Programmcode in Bytecode zur Verfügung steht, erfolgt die Ausführung deutlich schneller da die Kompilierung zur Laufzeit entfällt. Dies führt jedoch auch zu dem Problem, dass IDE-Funktionalitäten wie Autovervollständigung oder Syntax-Highlighting leider nicht verfügbar sind.

\subsection{Grundaufbau der Webseite}
Nun stellt sich die Frage: Welche Funktionen soll unsere Webseite haben? Zum einen brauchen wir natürlich Zugriff auf die Kamera des Nutzers, um den Videostream zu erhalten. Zum anderen benötigen wir eine Möglichkeit, das Ergebnis der Bildverarbeitung anzuzeigen.

Mithilfe eines Video-Elementes können wir den Kamerastream von Webkameras anzeigen und auf diesen zugreifen. Für die Anzeige der Bildverarbeitungsergebnisse habe ich mich für ein Canvas-Element entschieden. Warum? - In OpenCV gibt es viele Möglichkeiten, Zeichenvorgänge auf Matrizen anzuwenden. Diese Matrizen können dann auf ein Canvas-Element gezeichnet werden (mehr dazu weiter unten). Mein Plan ist somit alle relevanten Ergebnisse direkt auf den zu verarbeitenden Frame zu zeichnen und diesen dann auf dem Canvas-Element anzuzeigen.

Nach einigen Tests habe ich mich für folgende Struktur entschieden:
\begin{lstlisting}[style=HTML]
<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video Player mit Canvas Overlay</title>
    <link rel="stylesheet" href="style.css">
    <script src="lib/opencv_4.10.0.js"></script>
</head>
<body>
<div id="mainContainer">
    <div id="textContainer">
        <h1>CoinFinder</h1>
        <h3>Aktueller Wert: <span id="value">0</span></h3>
    </div>
    <div class="container" id="videoContainer">
        <video id="video" width="720" height="540" autoplay muted loop></video>
        <canvas id="outputCanvas" width="720" height="540"></canvas>
    </div>
</div>
</body>
</html>
\end{lstlisting}

Damit haben wir ein Video-Element, welches den Kamerastream anzeigt und ein Canvas-Element, um die Bildverarbeitungsergebnisse anzuzeigen. In der nachfolgenden CSS-Datei sorge ich dafür, dass beide Elemente stets übereinander liegen und die gleiche Größe haben. So sieht der Nutzer immer das aktuelle Kamerabild und die Bildverarbeitungsergebnisse direkt darüber. Zusätzlich bekommt der Canvas die Eigenschaft "image-rendering: pixelated;", damit auch kleine Matrizen originalgetreu dargestellt werden.

Die CSS-Datei sieht wie folgt aus:

\begin{lstlisting}[style=CSS]
    *{
        box-sizing: border-box;
    }
    
    html, body {
        background-color: #18204d;
        color: #ffffff;
        font-family: Arial, Helvetica, sans-serif;
    }
    
    h3{
        margin: 0 0 0 1em;
    }
    
    #mainContainer{
        position: relative;
        width: 97vw;
        height: 97dvh;
        display: flex;
        flex-direction: column;
    }
    
    #textContainer{
        display: flex;
        align-items: center;
    }
    
    #textContainer > *{
        margin: 0 1em 0 1em;
    }
    
    button{
        background-color: #ffa300;
        color: #18204d;
        border: none;
        padding: 0.5em 1em;
        font-size: 1em;
        cursor: pointer;
    }
    
    #videoContainer{
        position: relative;
        height: 100%;
        width: 100%;
        flex-grow: 1;
        align-items: center;
        justify-content: center;
        display: flex;
    
    }
    
    #video, #outputCanvas {
        height: 100%;
        width: 100%;
        left: 0;
        top: 0;
        position: absolute;
        aspect-ratio: inherit;
        object-fit: contain;
    }
    
    #outputCanvas{
        image-rendering: pixelated;
    }
    
    #mainContainer{
        border: 0.5em solid #ffa300;
    }
    
    #videoContainer{
        border: 0.5em solid blue;
    }
    
\end{lstlisting}

Als nächstes braucht es nun grundlegende Methoden, um auf die Kamera des Nutzers zuzugreifen und den Videostream auf dem Video-Element anzuzeigen.

\subsection{Grundlegende openCV Methoden}
Um auf die Kamera des Nutzers zuzugreifen, kann man unter anderem ein openCV-VideoCapture-Objekt verwenden. Dieses Objekt kann entweder direkt auf ein Video-Element zugreifen oder auf eine Datei. Da wir in unserem Fall den Kamerastream verwenden wollen, greifen wir direkt auf das Video-Element zu. Für den Zugriff auf die Webkamera benötigen wir die getUserMedia()-Methode des MediaDevices-Interfaces. Um sicherzustellen, dass openCV vollständig geladen ist, warten wir zusätzlich auf das "load"-Event des Fensters und initialisieren erst dann die Kamera:

\begin{lstlisting}[style=JavaScript]
    window.addEventListener("load", function () {
        video = document.getElementById('video');
        outputCanvas = document.getElementById('outputCanvas');
        videoContainer = document.getElementById('videoContainer');

        // get the camera
        navigator.mediaDevices.getUserMedia({
            video: true,
            audio: false
        }).then(stream => {
            video.srcObject = stream;
            video.onloadedmetadata = () => {
                video.play()

                //print camera stats
                console.log("Camera resolution: " + video.videoWidth + "x" + video.videoHeight);
                console.log("Camera frame rate: " + stream.getVideoTracks()[0].getSettings().frameRate+ " fps");

                //initialize the inputMat-Matrix
                inputMat = new cv.Mat(video.height, video.width, cv.CV_8UC4);
                guiMat = new cv.Mat(video.height, video.width, cv.CV_8UC4);
                videoCapture = new cv.VideoCapture(video);

                //check if everything is loaded
                cameraLoaded = true;
                console.log("Camera loaded");
                CheckIfLoadingFinished();
            };
        }).catch(error => {
            console.error('Error accessing the camera: ', error);
        });
    };
}
\end{lstlisting}

Nachdem die Kamera initialisiert ist, kann die read()-Methode des VideoCapture-Objekts verwendet werden, um den aktuellen Frame des Videostreams in eine openCV-Matrix zu konvertieren:

\begin{lstlisting}[style=JavaScript]
let inputMat;
let guiMat;

videoCapture.read(inputMat);
\end{lstlisting}

Für die nachfolgenden Funktionen werde ich immer wieder die Variablen \texttt{inputMat} und \texttt{guiMat} verwenden. \texttt{inputMat} enthält den aktuellen Frame des Videostreams, während \texttt{guiMat} eine Kopie des Frames ist, auf welchem die Bildverarbeitungsergebnisse gezeichnet werden. 

Nun brauchen wir jedoch noch eine Methode, um eine openCV-Matrix (in meinem Fall \texttt{guiMat}) auf einem Canvas ausgeben zu können. Dafür können wir einfach die cv.imshow()-Methode verwenden, welche eine Matrix auf ein Canvas-Element zeichnet. In unserem Fall verwenden wir das outputCanvas-Element, welches über dem Video-Element liegt. Die Funktion zum Anzeigen einer openCV-Matrix sieht wie folgt aus:

\begin{lstlisting}[style=JavaScript]
function ShowMatrix(src, canvas){
    cv.imshow(canvas, src);
}
\end{lstlisting}

Hinweis zur Speicherfreigabe: openCV.js verwaltet den Speicher nicht automatisch, wie es bei JavaScript üblich ist. Das bedeutet, dass wir selbst dafür verantwortlich sind, den Speicher freizugeben, sobald wir ihn nicht mehr benötigen. Dies betrifft hauptsächlich Objekte vom Typ cv.Mat und cv.MatVector, welche wir mit der delete()-Methode freigeben können. Tun wir dies nicht, verbraucht die Anwendung mit jedem neuen Aufruf von new cv.Mat() oder cv.imread() mehr Speicher, bis irgendwann der Browsertab abstürzt. Sollte dein Programm nach einigen Sekunden oder Minuten aufhören zu funktionieren, könnte dies ein Hinweis auf ein Speicherleck sein. Schaue in diesem Fall in die Konsole nach einer entsprechenden Fehlermeldung.

Zu guter Letzt benötigen wir noch eine Hauptschleife, bei der die Bilddaten aus dem Video-Element extrahiert, die zukünftigen Bildverarbeitungsalgorithmen ausgeführt und das Ergebnis auf dem Canvas-Element anzeigt werden. Dafür können wir entweder die \texttt{requestAnimationFrame()}-Methode verwenden, welche die Ausführung der Methode automatisch der Bildschirmwiederholrate anpasst, oder wir benutzen \texttt{setTimeout()} um selber die Zeit zwischen der wiederholten Ausführung festzulegen. Ich habe zusätzlich einen Bool "loopActive" hinzugefügt, um den Loop bei Bedarf auch nur einmalig ausführen zu können. Die Funktion sieht schließlich so aus:

\begin{lstlisting}[style=JavaScript]
let waitingForAnimationFrame = false;
function mainLoop() {
    if(!loadingFinished){
        console.warn("Can't start the loop because something is not loaded yet");
        return;
    }

    waitingForAnimationFrame = false;

    console.log("--- loop started");

    videoCapture.read(inputMat);
    videoCapture.read(guiMat);

    //do something with the matrix
    
    ShowMatrix(guiMat, outputCanvas);

    if(loopActive){
        waitingForAnimationFrame = true;
        requestAnimationFrame(mainLoop);
    }

    console.log("--- loop ended");
}
\end{lstlisting}

Nun haben wir das Grundgerüst für unsere Webseite erstellt. Als nächstes können wir uns an die Implementierung der ersten Bildverarbeitungsalgorithmen wie der Kreiserkennung machen. Mehr dazu gibt es im nächsten Eintrag. Bis bald!
